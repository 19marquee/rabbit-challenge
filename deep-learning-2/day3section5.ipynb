{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day3section5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXWq6p5HVwcTYfS6SJIUVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/19marquee/rabbit-challenge/blob/main/deep-learning-2/day3section5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRvTMNra91cL"
      },
      "source": [
        "# レポート 深層学習day3/Section5:Seq2Seq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zBbJNUdCNmD"
      },
      "source": [
        "## 100文字以内の要点のまとめ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqLDjSvkCN5A"
      },
      "source": [
        "- Seq2Seq(Sequence to Sequenceモデル)：Encoder-Decoderモデルの1種で、時系列データを入力し、時系列データを出力するモデルである。\n",
        "- 機械翻訳や文章要約などに使用される。\n",
        "- 1 hot vector：文章を単語などのトークンと呼ばれる単位に分割し、IDを割り当てる。\n",
        "- 単語埋め込み（Embedding）：このIDからそのトークンを表す分散表現ベクトルに変換する。単語の特徴を反映したベクトルを得る。\n",
        "- HRED(The Hierarchical Recurrent Encoder^Decoder)：単語単位ではんく、文脈の情報を取り入れたベクトルを変換してモデルに対応する構造を持たせたモデル。（Seq2Seqは文脈を考慮できない。）\n",
        "- オートエンコーダ：教師なし学習の1種。教師データを必要としない。入力データを出力側で復元するように学習を行う。\n",
        "- VAE(Variational Autoencoder)：潜在変数zに確率分布N(0,1)を仮定したモデルで、データをzの確率分布（という構造）に落とし込むことができる。通常のオートエンコーダ―において、潜在変数zに何かしらデータを押し込めているが、その構造がどのような状態か不明だという課題に対して対応。\n",
        "- 実際にVAEを学習を行う場合、より汎用性の高い特徴を掴むために、Encoderと潜在変数zの間にノイズを付与する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU616UZdD9Cs"
      },
      "source": [
        "##実装演習結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjNjkn2rXGpu"
      },
      "source": [
        "該当なしのため、省略します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKCe0Z0r1FEl"
      },
      "source": [
        "##確認テスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cfc-i7L1E9e"
      },
      "source": [
        "・下記の選択肢から、seq2seqについて説明しているものを選べ。  \n",
        "(1)時刻に関して順方向と逆方向のRNNを構成し、それら２つの中間層表現を特徴量として利用するものである。  \n",
        "(2)RNNを用いたEncoder-Decoderモデルの一種であり、機械翻訳などのモデルに使われる。  \n",
        "(3)構文木などの木構造に対して、隣接単語から表現ベクトル（フレーズ）を作るという演算を再帰的に行い（重みは共通）、文全体の表現ベクトルを得るニューラルネットワークである。  \n",
        "(4)RNNの一種であり、単純なRNNにおいて問題となる勾配消失問題をCECとゲートの概念を導入することで解決したものである。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acJh68u81TSP"
      },
      "source": [
        "解答  \n",
        "(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryh2b0BKaHS2"
      },
      "source": [
        "・Seq2seqとHRED、HREDとVHREDの違いを簡潔に述べよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aTQPix6aTZP"
      },
      "source": [
        "解答  \n",
        "\n",
        "Seq2Seqは、モデルの挙動、処理に文脈が考慮されない。単語間の1問1答しかできない。\n",
        "対して、HREDは文章の過去の文脈というものを考慮するContextRNNという仕組みを持つ。\n",
        "\n",
        "HREDは確かに文脈を意識した文を作る事ができるのだが、「うん」「そうだね」等のありがちな答えしか出さなくなる場合がある。\n",
        "対して、VHREDは文脈を意識しながら文を生成するモデルにバリエーションを持たせられるように工夫を施した仕組みである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2CCOkuYassY"
      },
      "source": [
        "・ＶＡＥに関する下記の説明文中の空欄に当てはまる言葉を答えよ。  \n",
        "自己符号化器の潜在変数に____を導入したもの。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJp2EEp3ax8E"
      },
      "source": [
        "解答  \n",
        "\n",
        "確率分布"
      ]
    }
  ]
}