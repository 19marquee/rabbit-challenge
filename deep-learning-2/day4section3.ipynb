{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day4section3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNw/LkW88Qjt7vGGBmv2Fjn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/19marquee/rabbit-challenge/blob/main/deep-learning-2/day4section3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRvTMNra91cL"
      },
      "source": [
        "# レポート 深層学習day4/Section3:軽量化・高速化技術"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zBbJNUdCNmD"
      },
      "source": [
        "## 100文字以内の要点のまとめ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqLDjSvkCN5A"
      },
      "source": [
        "- 分散深層学習：データ並列、モデル並列、GPUによる高速技術は、必要不可欠。\n",
        "- データ並列：データを分割し、各ワーカー（計算資源）毎に計算させる。同期型のパラメータの更新では、各ワーカーが計算が終わるのを持ち、全ワーカーの勾配が算出されたところで勾配の平均を算出し、親モデルのパラメータを更新する。非同期型では、各ワーカーそれぞれが子モデルのパラメータ更新を行う。学習が終わった子モデルはパラメータサーバを通してやりとりされる。非同期型の方が計算を待つ時間がない分速いが、学習は不安定になりやすい。\n",
        "- 現在は良い精度が出やすい同期型が主流である。\n",
        "- モデル並列：親モデルを各ワーカーに分割し、それぞれのモデルを学習させる。全てのデータで学習が終わった後で、一つのモデルに復元。モデルの層が枝分かれしている部分を分割したりする。\n",
        "- モデルが大きい時→モデル並列化。データが大きい時→データ並列化。\n",
        "- GPU：比較的低性能なコアが多数あり、簡単な並列処理が得意。ニューラルネットの学習は単純な行列演算が多いので、高速化が可能である。\n",
        "- 深層学習をGPUで行うためのライブラリとして、CUDA、OpenCLがある。CUDAはNVIDIA社開発のGPUのみで動作する。\n",
        "- 量子化：重みの精度を下げて、計算の高速化と省メモリ化を行う技術。\n",
        "- 蒸留：複雑で精度の良い教師モデルから、軽量な生徒モデルを効率よく学習させる技術。\n",
        "- プルーニング：寄与の少ない（あまりモデルの性能に影響のない）ニューロンをモデルから削減して、高速化と省メモリ化を行う技術。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU616UZdD9Cs"
      },
      "source": [
        "##実装演習結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjNjkn2rXGpu"
      },
      "source": [
        "該当なしのため、省略します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKCe0Z0r1FEl"
      },
      "source": [
        "##確認テスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcFf8CdclMaf"
      },
      "source": [
        "該当なしのため、省略します。"
      ]
    }
  ]
}