{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "information-theory.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM95tM65HLTsXV7jjz8mGue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/19marquee/rabbit-challenge/blob/main/applied-mathematics/information_theory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m0xL6bNZycs"
      },
      "source": [
        "# レポート 応用数学/第三章：情報理論\n",
        "### 100文字以上の要点のまとめ\n",
        "- 元の数/量に対しての増え方の違い、つまり、増加の「比率」を考える。  \n",
        "例:  \n",
        "1減って、10になった。$\\dfrac{\\Delta w}{w} = \\dfrac{1}{10}$  \n",
        "1減って、1になった。$\\dfrac{\\Delta w}{w} = \\dfrac{1}{1} $\n",
        "- 自己情報量\n",
        "$$\n",
        "I(x) = -\\log(P(x)) = \\log(W(x))\n",
        "$$\n",
        "$P(x)$は確率、$W(x)$は事象の回数を表す。($W(x) = \\dfrac{1}{P(x)}$)\n",
        "- シャノンエントロピー  \n",
        "自己情報量の期待値。\n",
        "$$\n",
        "H(x) = E(I(x)) = -E(\\log(P(x))) = -\\sum(P(x)\\log(P(x)))\n",
        "$$\n",
        "- カルバック・ライブラー　ダイバージェンス  \n",
        "同じ事象・確率変数における確率分布P,Qの違いを表す尺度。距離のようなものだが、距離の定義は満たさない（KLダイバージェンスは距離ではない）。\n",
        "$$\n",
        "D_{KL}(P||Q) = E_{x～P}[\\log\\dfrac{P(x)}{Q(x)}] = \\sum_x P(x)\\log \\dfrac{P(x)}{Q(x)}\n",
        "$$\n",
        "- 交差エントロピー  \n",
        "$$\n",
        "H(P,Q) = -E_{x～P}\\log Q(x) = -\\sum_x P(x)\\log Q(x)\n",
        "$$\n",
        "KLダイバージェンスの一部分を取り出したもの。\n",
        "Qについての自己情報量をPの分布で平均している。\n",
        "$D_{KL}(P||Q) = \\sum_x P(x)\\log \\dfrac{P(x)}{Q(x)} = \\sum_x P(x)(-\\log(Q(x)))-(-\\log(P(x)))$より、\n",
        "$H(P,Q) = H(P)+D_{KL}(P||Q)$と表せる。\n",
        "\n"
      ]
    }
  ]
}